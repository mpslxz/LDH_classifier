import numpy as np
import theano.tensor as T
from theano_ops.Ops import dense
from theano_ops.activations import softmax, sigmoid
from theano_ops.base_model import TheanoModel
from theano_ops.utils import to_categorical
from theano_ops.optimizers import Adam


class SpineClassifier(TheanoModel):
    def _def_tensors(self):
        self.x = T.matrix('x', 'float32')
        self.y = T.matrix('y', 'int8')

    def _def_cost_acc(self):
        self.cost = T.nnet.binary_crossentropy(self.outputs, self.y).mean()
        diff = abs(T.argmax(self.outputs, axis=1) - T.argmax(self.y, axis=1))
        self.acc = T.sub(1, 1.*T.nonzero(diff)[0].shape[0] / self.y.shape[0])

    def _def_arch(self, init_params=None):
        params = self.get_params('d1', init_params)
        self.dense1, param = dense(self.x, self.get_shape(self.x)[1], 50, layer_name='d1', init_params=params)
        self.params += params

        params = self.get_params('d2', init_params)
        self.dense2, params = dense(sigmoid(self.dense1), self.get_shape(self.dense1)[1], 30, layer_name='d2', init_params=params)

        params = self.get_params('d3', init_params)
        self.dense3, params = dense(sigmoid(self.dense2), self.get_shape(self.dense2)[1], 2, layer_name='d3', init_params=params)

        self.logits = softmax(self.dense3)
        self.outputs = self.logits

if __name__ == "__main__":
    x_train = np.load('train_x.npy').astype('float32')
    y_train = to_categorical(np.load('train_y.npy')).astype('int8')

    x_test = np.load('test_x.npy').astype('float32')
    y_test = to_categorical(np.load('test_y.npy')).astype('int8')

    M = SpineClassifier(batch_size=32, input_shape=(1, 252), optimizer=Adam(lr=1e-4), metrics=['loss', 'acc'])
    M.train(x_train=x_train, y_train=y_train, x_validation=x_test, y_validation=y_test, nb_epochs=100)
    